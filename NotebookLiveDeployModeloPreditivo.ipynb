{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "machine_shape": "hm",
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "f2bH3Fovgj1S",
    "ExecuteTime": {
     "end_time": "2024-05-15T00:05:54.287504Z",
     "start_time": "2024-05-15T00:05:53.387960Z"
    }
   },
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "# URL do site IPEADATA\n",
    "url = 'http://www.ipeadata.gov.br/ExibeSerie.aspx?module=m&serid=1650971490&oper=view'\n",
    "\n",
    "# Faz uma requisição GET ao site e captura a resposta\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verifica se a requisição foi bem sucedida\n",
    "if response.status_code == 200:\n",
    "    # Cria um objeto BeautifulSoup para analisar o HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Procura pela tabela no HTML analisado (o id ou classe pode variar)\n",
    "    # Você precisaria inspecionar o HTML para obter o seletor correto\n",
    "    table = soup.find('table', {'id': 'grd_DXMainTable'})\n",
    "\n",
    "    # Usa o pandas para ler a tabela HTML diretamente para um DataFrame\n",
    "    df = pd.read_html(str(table),skiprows=0)[0]\n",
    "\n",
    "    df.columns = df.iloc[0]\n",
    "    df = df.drop(0)\n",
    "\n",
    "    # Mostra as primeiras linhas do DataFrame\n",
    "    df.head()\n",
    "else:\n",
    "    print('Falha ao acessar a página: Status Code', response.status_code)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <bound method IPythonKernel._clean_thread_parent_frames of <ipykernel.ipkernel.IPythonKernel object at 0x7f3d77812650>>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/fredg/miniconda3/envs/tensorflow/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 775, in _clean_thread_parent_frames\n",
      "    def _clean_thread_parent_frames(\n",
      "\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mbs4\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BeautifulSoup\n\u001B[0;32m----> 3\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# URL do site IPEADATA\u001B[39;00m\n\u001B[1;32m      6\u001B[0m url \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mhttp://www.ipeadata.gov.br/ExibeSerie.aspx?module=m&serid=1650971490&oper=view\u001B[39m\u001B[38;5;124m'\u001B[39m\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/__init__.py:139\u001B[0m\n\u001B[1;32m    121\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcore\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mreshape\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m    122\u001B[0m     concat,\n\u001B[1;32m    123\u001B[0m     lreshape,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    135\u001B[0m     qcut,\n\u001B[1;32m    136\u001B[0m )\n\u001B[1;32m    138\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m api, arrays, errors, io, plotting, tseries\n\u001B[0;32m--> 139\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m testing\n\u001B[1;32m    140\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_print_versions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m show_versions\n\u001B[1;32m    142\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mio\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m    143\u001B[0m     \u001B[38;5;66;03m# excel\u001B[39;00m\n\u001B[1;32m    144\u001B[0m     ExcelFile,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    172\u001B[0m     read_spss,\n\u001B[1;32m    173\u001B[0m )\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/testing.py:6\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mPublic testing utility functions.\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_testing\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m      7\u001B[0m     assert_extension_array_equal,\n\u001B[1;32m      8\u001B[0m     assert_frame_equal,\n\u001B[1;32m      9\u001B[0m     assert_index_equal,\n\u001B[1;32m     10\u001B[0m     assert_series_equal,\n\u001B[1;32m     11\u001B[0m )\n\u001B[1;32m     13\u001B[0m __all__ \u001B[38;5;241m=\u001B[39m [\n\u001B[1;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_extension_array_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_frame_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_series_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124massert_index_equal\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m     18\u001B[0m ]\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/_testing/__init__.py:42\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     29\u001B[0m     ArrowDtype,\n\u001B[1;32m     30\u001B[0m     DataFrame,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     34\u001B[0m     Series,\n\u001B[1;32m     35\u001B[0m )\n\u001B[1;32m     36\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_testing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_io\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     37\u001B[0m     round_trip_localpath,\n\u001B[1;32m     38\u001B[0m     round_trip_pathlib,\n\u001B[1;32m     39\u001B[0m     round_trip_pickle,\n\u001B[1;32m     40\u001B[0m     write_to_compressed,\n\u001B[1;32m     41\u001B[0m )\n\u001B[0;32m---> 42\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_testing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_warnings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     43\u001B[0m     assert_produces_warning,\n\u001B[1;32m     44\u001B[0m     maybe_produces_warning,\n\u001B[1;32m     45\u001B[0m )\n\u001B[1;32m     46\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_testing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01masserters\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     47\u001B[0m     assert_almost_equal,\n\u001B[1;32m     48\u001B[0m     assert_attr_equal,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     69\u001B[0m     raise_assert_detail,\n\u001B[1;32m     70\u001B[0m )\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_testing\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m (\n\u001B[1;32m     72\u001B[0m     get_dtype,\n\u001B[1;32m     73\u001B[0m     get_obj,\n\u001B[1;32m     74\u001B[0m )\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1176\u001B[0m, in \u001B[0;36m_find_and_load\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:1147\u001B[0m, in \u001B[0;36m_find_and_load_unlocked\u001B[0;34m(name, import_)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:676\u001B[0m, in \u001B[0;36m_load_unlocked\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:579\u001B[0m, in \u001B[0;36mmodule_from_spec\u001B[0;34m(spec)\u001B[0m\n",
      "File \u001B[0;32m<frozen importlib._bootstrap>:542\u001B[0m, in \u001B[0;36m_init_module_attrs\u001B[0;34m(spec, module, override)\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "8pq_4FuVHFIN"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "WD-ifgatyrVv",
    "outputId": "37f9c353-7545-4e03-8332-41ceae6ff0e9"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Função para atualizar o DataFrame com novos dados\n",
    "def update_dataframe(df, new_data):\n",
    "    # Converte a coluna 'Data' para datetime\n",
    "    df['Data'] = pd.to_datetime(df['Data'], dayfirst=True)\n",
    "    new_data['Data'] = pd.to_datetime(new_data['Data'], dayfirst=True)\n",
    "\n",
    "    # Encontra a data mais recente no DataFrame existente\n",
    "    last_date = df['Data'].max()\n",
    "\n",
    "    # Filtra as novas linhas que são mais recentes do que a última data\n",
    "    new_rows = new_data[new_data['Data'] > last_date]\n",
    "\n",
    "    # Concatena os novos dados com o DataFrame existente se houver novas linhas\n",
    "    if not new_rows.empty:\n",
    "        updated_df = pd.concat([df, new_rows], ignore_index=True)\n",
    "    else:\n",
    "        updated_df = df\n",
    "\n",
    "    return updated_df\n",
    "\n",
    "# URL do site IPEADATA\n",
    "url = 'http://www.ipeadata.gov.br/ExibeSerie.aspx?module=m&serid=1650971490&oper=view'\n",
    "\n",
    "# Faz uma requisição GET ao site e captura a resposta\n",
    "response = requests.get(url)\n",
    "\n",
    "# Verifica se a requisição foi bem sucedida\n",
    "if response.status_code == 200:\n",
    "    # Cria um objeto BeautifulSoup para analisar o HTML\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    # Procura pela tabela no HTML analisado\n",
    "    table = soup.find('table', {'id': 'grd_DXMainTable'})\n",
    "    # Usa o pandas para ler a tabela HTML diretamente para um DataFrame\n",
    "    new_df = pd.read_html(str(table), header=0)[0]\n",
    "\n",
    "    # Verifica se o arquivo do DataFrame existe e carrega, ou cria um novo DataFrame se não existir\n",
    "    path = '/content/ipea.csv'\n",
    "    try:\n",
    "        existing_df = pd.read_csv(path)\n",
    "    except FileNotFoundError:\n",
    "        existing_df = new_df  # Se o arquivo não existir, considere os dados atuais como o DataFrame existente\n",
    "\n",
    "    # Atualiza o DataFrame existente com novos dados (carga incremental)\n",
    "    updated_df = update_dataframe(existing_df, new_df)\n",
    "\n",
    "    updated_df['Preço - petróleo bruto - Brent (FOB)'] = updated_df['Preço - petróleo bruto - Brent (FOB)']/100\n",
    "\n",
    "    # Salva o DataFrame atualizado para o arquivo\n",
    "    updated_df.to_csv(path, index=False)\n",
    "\n",
    "    # Mostra as primeiras linhas do DataFrame atualizado\n",
    "    updated_df.head()\n",
    "else:\n",
    "    print('Falha ao acessar a página: Status Code', response.status_code)"
   ],
   "metadata": {
    "id": "Z2cWmysNGCCz"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "updated_df.info()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3pIYmay3GquB",
    "outputId": "1478fb2e-bc88-423a-84b0-329df7563ca7"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import Adam\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Definir o dispositivo para a GPU se disponível\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Carregar o DataFrame\n",
    "df = pd.read_csv('/content/ipea.csv')\n",
    "\n",
    "# Converter a coluna de data para datetime e depois para timestamp Unix\n",
    "df['Data'] = pd.to_datetime(df['Data'], dayfirst=True)\n",
    "df = df.sort_values(by='Data',ascending=True)\n",
    "df['Timestamp'] = df['Data'].values.astype('int64') // 10**9\n",
    "\n",
    "# Escalar a coluna de preços, já que os modelos de DL geralmente funcionam melhor com dados normalizados\n",
    "scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "df['Preço - petróleo bruto - Brent (FOB)'] = scaler.fit_transform(df['Preço - petróleo bruto - Brent (FOB)'].values.reshape(-1, 1)).astype('float32')\n",
    "\n",
    "# Preparar dados para o PyTorch\n",
    "X = df['Timestamp'].values.astype('float32')  # A entrada do modelo será o timestamp\n",
    "y = df['Preço - petróleo bruto - Brent (FOB)'].values.astype('float32')  # A saída do modelo serão os preços\n",
    "\n",
    "# Dividir o conjunto de dados em treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "\n",
    "# Converter os dados para Tensor\n",
    "X_train_tensor = torch.tensor(X_train).view(-1, 1, 1)\n",
    "y_train_tensor = torch.tensor(y_train).view(-1, 1, 1)\n",
    "X_test_tensor = torch.tensor(X_test).view(-1, 1, 1)\n",
    "y_test_tensor = torch.tensor(y_test).view(-1, 1, 1)\n",
    "\n",
    "# Mover para o dispositivo apropriado\n",
    "X_train_tensor = X_train_tensor.to(device)\n",
    "y_train_tensor = y_train_tensor.to(device)\n",
    "X_test_tensor = X_test_tensor.to(device)\n",
    "y_test_tensor = y_test_tensor.to(device)\n",
    "\n",
    "# Definir o modelo LSTM\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size=1, hidden_layer_size=200, output_size=1):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size, hidden_layer_size ,num_layers=3)\n",
    "\n",
    "        self.linear = nn.Linear(hidden_layer_size, output_size)\n",
    "\n",
    "    def forward(self, input_seq):\n",
    "        lstm_out, _ = self.lstm(input_seq)\n",
    "        predictions = self.linear(lstm_out.view(len(input_seq), -1))\n",
    "        return predictions[-1]\n",
    "\n",
    "# Instanciar o modelo\n",
    "model = LSTMModel().to(device)\n",
    "\n",
    "# Definir a função de perda e o otimizador\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# Treinar o modelo\n",
    "epochs = 10\n",
    "for i in range(epochs):\n",
    "    for seq, labels in zip(X_train_tensor, y_train_tensor):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        model.hidden = (torch.zeros(1, 1, model.hidden_layer_size).to(device),\n",
    "                        torch.zeros(1, 1, model.hidden_layer_size).to(device))\n",
    "\n",
    "        y_pred = model(seq)\n",
    "\n",
    "        single_loss = loss_function(y_pred, labels)\n",
    "        single_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        print(f'Epoch {i} loss: {single_loss.item()}')\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    preds = []\n",
    "    for i in range(len(X_test)):\n",
    "        seq = X_test_tensor[i : i + 1]\n",
    "        preds.append(model(seq).cpu().numpy()[0])\n",
    "\n",
    "# Inverter a escala dos preços para a escala original\n",
    "actual_predictions = scaler.inverse_transform(np.array(preds).reshape(-1, 1))\n",
    "\n",
    "# Plotar\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.plot(df.index[-len(actual_predictions):], actual_predictions, label='Predicted')\n",
    "plt.plot(df.index[-len(actual_predictions):], scaler.inverse_transform(y_test.reshape(-1,1)), label='Actual')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "o2B8GIMTUzgs",
    "outputId": "de012de2-b1f1-4fdf-fc38-2efe1934170c"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Prever usando o conjunto de teste\n",
    "predictions = []\n",
    "with torch.no_grad():\n",
    "    for i in range(len(X_test)):\n",
    "        seq = X_test_tensor[i : i+1]\n",
    "        predictions.append(model(seq).item())\n",
    "predictions = np.array(predictions).reshape(-1, 1)\n",
    "predictions = scaler.inverse_transform(predictions) # Reverter escala dos dados de previsão\n",
    "\n",
    "# Reverter escala dos dados reais de teste\n",
    "actual = scaler.inverse_transform(y_test.reshape(-1,1))\n",
    "\n",
    "# Plotagem do gráfico\n",
    "plt.figure(figsize=(15,6))\n",
    "plt.plot(df['Data'].iloc[-len(predictions):], actual, label='Actual Data')\n",
    "plt.plot(df['Data'].iloc[-len(predictions):], predictions, label='Predicted Data')\n",
    "plt.legend()\n",
    "plt.title('Preços reais vs previsões')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 564
    },
    "id": "BhxdtA0Wcm8b",
    "outputId": "b0df4e57-ac8f-4d33-9d50-911b6814db96"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o DataFrame\n",
    "df = pd.read_csv('/content/ipea.csv')\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "df = df.sort_values(by='Data', ascending=True).reset_index(drop=True)\n",
    "#df['Data'] = pd.to_datetime(df['Data'], dayfirst=True)\n",
    "#df['Preço'] = df['Preço'].astype(float)  # Certifique-se de que os preços são float\n",
    "\n",
    "# É uma boa prática criar recursos de atraso (lag features) para séries temporais\n",
    "# Vamos criar alguns para nosso modelo\n",
    "for lag in range(1, 2):  # Criar atrasos de 1 dia até 3 dias\n",
    "    df[f'Preço_lag_{lag}'] = df['Preço - petróleo bruto - Brent (FOB)'].shift(lag)\n",
    "\n",
    "# Removemos quaisquer linhas com valores NaN que foram criados ao fazer o shift\n",
    "df = df.dropna()\n",
    "\n",
    "# Preparando os dados para treinamento\n",
    "X = df[['Preço_lag_1']].values  # Inputs são os preços atrasados\n",
    "y = df['Preço - petróleo bruto - Brent (FOB)'].values  # Output é o preço atual\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False, random_state=42)\n",
    "\n",
    "# Criar e treinar o modelo de Gradient Boosting\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, loss='squared_error')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "\n",
    "# Opcional: Plotando resultados reais vs previstos. Tem que ter matplotlib instalado.\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(df['Data'].iloc[-len(y_test):], y_test, label='Real')\n",
    "plt.plot(df['Data'].iloc[-len(predictions):], predictions, label='Previsão')\n",
    "# Melhorar a formatação do eixo x\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))  # Formatar as datas como 'Ano-Mês-Dia'\n",
    "plt.gca().xaxis.set_major_locator(mdates.AutoDateLocator())             # Escolher automaticamente a localização das datas\n",
    "# Melhorar a legibilidade girando as datas e ajustando o espaçamento\n",
    "plt.gcf().autofmt_xdate()  # Gira as datas para evitar sobreposição\n",
    "plt.legend()\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço')\n",
    "plt.grid(True)\n",
    "plt.title('Preços Reais vs Previsões (Gradient Boosting)')\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 515
    },
    "id": "acX5b4pjuRxH",
    "outputId": "6054b831-e867-4390-dc74-732420448439"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "HlDvLkXD5lpa",
    "outputId": "796c82f9-c3c7-47aa-ac73-7b84d0343844"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "predictions_next_week = predictions[-7:]  # Ajustar o número conforme necessário\n",
    "df_next_week_dates = df['Data'].iloc[-len(y_test):][-7:]  # Ajustar o número conforme necessário\n",
    "\n",
    "# Plotar os resultados\n",
    "plt.figure(figsize=(10, 5))\n",
    "# Certifique-se de reverter os dados para que as datas sejam plotadas em ordem cronológica\n",
    "plt.plot(df_next_week_dates[::-1], predictions_next_week[::-1], label='Previsão', color='orange', marker='o')\n",
    "\n",
    "# Formatar o eixo x para apresentar as datas\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "plt.gcf().autofmt_xdate()  # Auto formatar as datas para evitar sobreposição\n",
    "\n",
    "plt.title('Previsão dos Preços para a Próxima Semana')\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço Previsto')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 481
    },
    "id": "IqNt6fxp5mEC",
    "outputId": "536a2680-0319-40df-ec0b-92211a1a0462"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "len(predictions)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MAoeDzQE-Vaq",
    "outputId": "4c3334bf-1cbc-40fd-980e-8a2bbd333c2e"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "X_train"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZdohgA-r-XdW",
    "outputId": "cc31b7de-57fd-4617-e2eb-dc207701ae33"
   },
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "\n",
    "# Carregar o DataFrame\n",
    "df = pd.read_csv('/content/ipea.csv')\n",
    "df['Data'] = pd.to_datetime(df['Data'])\n",
    "df = df.sort_values(by='Data', ascending=True).reset_index(drop=True)\n",
    "#df['Data'] = pd.to_datetime(df['Data'], dayfirst=True)\n",
    "#df['Preço'] = df['Preço'].astype(float)  # Certifique-se de que os preços são float\n",
    "\n",
    "# É uma boa prática criar recursos de atraso (lag features) para séries temporais\n",
    "# Vamos criar alguns para nosso modelo\n",
    "# Criar recursos de atraso (lag features)\n",
    "lags = 7\n",
    "for lag in range(1, lags + 1):\n",
    "    df[f'Preço_lag_{lag}'] = df['Preço - petróleo bruto - Brent (FOB)'].shift(lag)\n",
    "\n",
    "# Removemos quaisquer linhas com valores NaN que foram criados ao fazer o shift\n",
    "df = df.dropna()\n",
    "\n",
    "# Preparando os dados para treinamento\n",
    "X = df[['Preço_lag_1']].values  # Inputs são os preços atrasados\n",
    "y = df['Preço - petróleo bruto - Brent (FOB)'].values  # Output é o preço atual\n",
    "\n",
    "# Dividir os dados em conjuntos de treino e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=False)\n",
    "\n",
    "# Criar e treinar o modelo de Gradient Boosting\n",
    "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42, loss='squared_error')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Fazer previsões\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Avaliar o modelo\n",
    "mse = mean_squared_error(y_test, predictions)\n",
    "mae = mean_absolute_error(y_test, predictions)\n",
    "\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "# Fazer previsões para a próxima semana usando os últimos dados conhecidos\n",
    "last_known_data = X[-1].reshape(1, -1)\n",
    "next_week_predictions = []\n",
    "for _ in range(7):  # para cada dia da próxima semana\n",
    "    next_day_pred = model.predict(last_known_data)[0]\n",
    "    next_week_predictions.append(next_day_pred)\n",
    "    last_known_data = np.roll(last_known_data, -1)\n",
    "    last_known_data[0, -1] = next_day_pred\n",
    "\n",
    "# As datas correspondentes à próxima semana\n",
    "next_week_dates = pd.date_range(df['Data'].iloc[-1], periods=8)[1:]\n",
    "\n",
    "# Selecionar os dados da semana atual (últimos 7 dias do dataset)\n",
    "current_week_dates = df['Data'].iloc[-7:]\n",
    "current_week_prices = df['Preço - petróleo bruto - Brent (FOB)'].iloc[-7:]\n",
    "\n",
    "for week, pred in zip(next_week_dates, next_week_predictions):\n",
    "    print(f'{week}: {pred:.2f}')\n",
    "\n",
    "# Plotar os preços reais da semana atual e as previsões para a próxima semana\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(current_week_dates, current_week_prices, 'bo-', label='Preços Atuais')\n",
    "plt.plot(next_week_dates, next_week_predictions, 'r--o', label='Previsões para a Próxima Semana')\n",
    "\n",
    "# Formatar o eixo x para exibir datas\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())\n",
    "plt.gcf().autofmt_xdate()  # Ajustar formato das datas para evitar sobreposição\n",
    "\n",
    "plt.xlabel('Data')\n",
    "plt.ylabel('Preço')\n",
    "plt.title('Preços Reais e Previsões para as Últimas Duas Semanas')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "O1RwUAdFUsqC",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 639
    },
    "outputId": "551c1838-5320-46db-8121-0676fc9faf4c",
    "ExecuteTime": {
     "end_time": "2024-05-15T00:13:42.813699Z",
     "start_time": "2024-05-15T00:13:41.616098Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/ipea.csv'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 12\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mticker\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MaxNLocator\n\u001B[1;32m     11\u001B[0m \u001B[38;5;66;03m# Carregar o DataFrame\u001B[39;00m\n\u001B[0;32m---> 12\u001B[0m df \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mread_csv\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m/content/ipea.csv\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     13\u001B[0m df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mto_datetime(df[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[1;32m     14\u001B[0m df \u001B[38;5;241m=\u001B[39m df\u001B[38;5;241m.\u001B[39msort_values(by\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mData\u001B[39m\u001B[38;5;124m'\u001B[39m, ascending\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\u001B[38;5;241m.\u001B[39mreset_index(drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001B[0m, in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001B[0m\n\u001B[1;32m   1013\u001B[0m kwds_defaults \u001B[38;5;241m=\u001B[39m _refine_defaults_read(\n\u001B[1;32m   1014\u001B[0m     dialect,\n\u001B[1;32m   1015\u001B[0m     delimiter,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     dtype_backend\u001B[38;5;241m=\u001B[39mdtype_backend,\n\u001B[1;32m   1023\u001B[0m )\n\u001B[1;32m   1024\u001B[0m kwds\u001B[38;5;241m.\u001B[39mupdate(kwds_defaults)\n\u001B[0;32m-> 1026\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_read\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001B[0m, in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    617\u001B[0m _validate_names(kwds\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnames\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m))\n\u001B[1;32m    619\u001B[0m \u001B[38;5;66;03m# Create the parser.\u001B[39;00m\n\u001B[0;32m--> 620\u001B[0m parser \u001B[38;5;241m=\u001B[39m \u001B[43mTextFileReader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfilepath_or_buffer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    622\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m chunksize \u001B[38;5;129;01mor\u001B[39;00m iterator:\n\u001B[1;32m    623\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m parser\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001B[0m, in \u001B[0;36mTextFileReader.__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m   1617\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptions[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m kwds[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mhas_index_names\u001B[39m\u001B[38;5;124m\"\u001B[39m]\n\u001B[1;32m   1619\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles: IOHandles \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m-> 1620\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_engine \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_engine\u001B[49m\u001B[43m(\u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mengine\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001B[0m, in \u001B[0;36mTextFileReader._make_engine\u001B[0;34m(self, f, engine)\u001B[0m\n\u001B[1;32m   1878\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m mode:\n\u001B[1;32m   1879\u001B[0m         mode \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m-> 1880\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;241m=\u001B[39m \u001B[43mget_handle\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1881\u001B[0m \u001B[43m    \u001B[49m\u001B[43mf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1882\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1883\u001B[0m \u001B[43m    \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1884\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcompression\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcompression\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1885\u001B[0m \u001B[43m    \u001B[49m\u001B[43mmemory_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mmemory_map\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1886\u001B[0m \u001B[43m    \u001B[49m\u001B[43mis_text\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mis_text\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1887\u001B[0m \u001B[43m    \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mencoding_errors\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstrict\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1888\u001B[0m \u001B[43m    \u001B[49m\u001B[43mstorage_options\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43moptions\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mstorage_options\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mNone\u001B[39;49;00m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m   1889\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1890\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m   1891\u001B[0m f \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhandles\u001B[38;5;241m.\u001B[39mhandle\n",
      "File \u001B[0;32m~/miniconda3/envs/tensorflow/lib/python3.11/site-packages/pandas/io/common.py:873\u001B[0m, in \u001B[0;36mget_handle\u001B[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001B[0m\n\u001B[1;32m    868\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(handle, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m    869\u001B[0m     \u001B[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001B[39;00m\n\u001B[1;32m    870\u001B[0m     \u001B[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001B[39;00m\n\u001B[1;32m    871\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mencoding \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mb\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;129;01min\u001B[39;00m ioargs\u001B[38;5;241m.\u001B[39mmode:\n\u001B[1;32m    872\u001B[0m         \u001B[38;5;66;03m# Encoding\u001B[39;00m\n\u001B[0;32m--> 873\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\n\u001B[1;32m    874\u001B[0m \u001B[43m            \u001B[49m\u001B[43mhandle\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    875\u001B[0m \u001B[43m            \u001B[49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmode\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    876\u001B[0m \u001B[43m            \u001B[49m\u001B[43mencoding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mioargs\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mencoding\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    877\u001B[0m \u001B[43m            \u001B[49m\u001B[43merrors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43merrors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    878\u001B[0m \u001B[43m            \u001B[49m\u001B[43mnewline\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m    879\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    880\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    881\u001B[0m         \u001B[38;5;66;03m# Binary mode\u001B[39;00m\n\u001B[1;32m    882\u001B[0m         handle \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(handle, ioargs\u001B[38;5;241m.\u001B[39mmode)\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: '/content/ipea.csv'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "df"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "RREjOlq1V0Il",
    "outputId": "4f8ca9aa-b33c-4798-a298-3400c31bbff5"
   },
   "outputs": [],
   "execution_count": null
  }
 ]
}
